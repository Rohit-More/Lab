{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IRboViBPkxM",
        "outputId": "8e728b3c-c3e4-40df-a338-db8918c3a145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNjNdRltP1s8",
        "outputId": "b0f187d5-20a7-45a4-b6fb-8869471cff4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-s5fvvpf7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-s5fvvpf7\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=bc7b6aef6a4bed4cde81c528d2a3f04c869c9613cd51ce9c00258b528b2df235\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h6tehc17/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50wqueyJQHNl",
        "outputId": "03234a26-0301-4840-934b-559c973988b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "__global__ void vectorAdd(int* a, int* b, int* c, int size) \n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() \n",
        "{\n",
        "    int size = 100;  // Size of the vectors\n",
        "    int* a, * b, * c;    // Host vectors\n",
        "    int* dev_a, * dev_b, * dev_c;  // Device vectors\n",
        "\n",
        "    // Allocate memory for host vectors\n",
        "    a = (int*)malloc(size * sizeof(int));\n",
        "    b = (int*)malloc(size * sizeof(int));\n",
        "    c = (int*)malloc(size * sizeof(int));\n",
        "\n",
        "    // Initialize host vectors\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        a[i] = i;\n",
        "        b[i] = i;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on the device for device vectors\n",
        "    cudaMalloc((void**)&dev_a, size * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, size * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, size * sizeof(int));\n",
        "\n",
        "    // Copy host vectors to device\n",
        "    cudaMemcpy(dev_a, a, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel for vector addition\n",
        "    int blockSize = 256; //threads\n",
        "    int gridSize = (size + blockSize - 1) / blockSize;  //blocks\n",
        "    vectorAdd<<<gridSize, blockSize>>>(dev_a, dev_b, dev_c, size);\n",
        "\n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(c, dev_c, size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print result\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    // Free host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbA9p3joQK9q",
        "outputId": "06ebb60d-043d-46ec-f01b-ef77d03ec13d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 + 0 = 0\n",
            "1 + 1 = 2\n",
            "2 + 2 = 4\n",
            "3 + 3 = 6\n",
            "4 + 4 = 8\n",
            "5 + 5 = 10\n",
            "6 + 6 = 12\n",
            "7 + 7 = 14\n",
            "8 + 8 = 16\n",
            "9 + 9 = 18\n",
            "10 + 10 = 20\n",
            "11 + 11 = 22\n",
            "12 + 12 = 24\n",
            "13 + 13 = 26\n",
            "14 + 14 = 28\n",
            "15 + 15 = 30\n",
            "16 + 16 = 32\n",
            "17 + 17 = 34\n",
            "18 + 18 = 36\n",
            "19 + 19 = 38\n",
            "20 + 20 = 40\n",
            "21 + 21 = 42\n",
            "22 + 22 = 44\n",
            "23 + 23 = 46\n",
            "24 + 24 = 48\n",
            "25 + 25 = 50\n",
            "26 + 26 = 52\n",
            "27 + 27 = 54\n",
            "28 + 28 = 56\n",
            "29 + 29 = 58\n",
            "30 + 30 = 60\n",
            "31 + 31 = 62\n",
            "32 + 32 = 64\n",
            "33 + 33 = 66\n",
            "34 + 34 = 68\n",
            "35 + 35 = 70\n",
            "36 + 36 = 72\n",
            "37 + 37 = 74\n",
            "38 + 38 = 76\n",
            "39 + 39 = 78\n",
            "40 + 40 = 80\n",
            "41 + 41 = 82\n",
            "42 + 42 = 84\n",
            "43 + 43 = 86\n",
            "44 + 44 = 88\n",
            "45 + 45 = 90\n",
            "46 + 46 = 92\n",
            "47 + 47 = 94\n",
            "48 + 48 = 96\n",
            "49 + 49 = 98\n",
            "50 + 50 = 100\n",
            "51 + 51 = 102\n",
            "52 + 52 = 104\n",
            "53 + 53 = 106\n",
            "54 + 54 = 108\n",
            "55 + 55 = 110\n",
            "56 + 56 = 112\n",
            "57 + 57 = 114\n",
            "58 + 58 = 116\n",
            "59 + 59 = 118\n",
            "60 + 60 = 120\n",
            "61 + 61 = 122\n",
            "62 + 62 = 124\n",
            "63 + 63 = 126\n",
            "64 + 64 = 128\n",
            "65 + 65 = 130\n",
            "66 + 66 = 132\n",
            "67 + 67 = 134\n",
            "68 + 68 = 136\n",
            "69 + 69 = 138\n",
            "70 + 70 = 140\n",
            "71 + 71 = 142\n",
            "72 + 72 = 144\n",
            "73 + 73 = 146\n",
            "74 + 74 = 148\n",
            "75 + 75 = 150\n",
            "76 + 76 = 152\n",
            "77 + 77 = 154\n",
            "78 + 78 = 156\n",
            "79 + 79 = 158\n",
            "80 + 80 = 160\n",
            "81 + 81 = 162\n",
            "82 + 82 = 164\n",
            "83 + 83 = 166\n",
            "84 + 84 = 168\n",
            "85 + 85 = 170\n",
            "86 + 86 = 172\n",
            "87 + 87 = 174\n",
            "88 + 88 = 176\n",
            "89 + 89 = 178\n",
            "90 + 90 = 180\n",
            "91 + 91 = 182\n",
            "92 + 92 = 184\n",
            "93 + 93 = 186\n",
            "94 + 94 = 188\n",
            "95 + 95 = 190\n",
            "96 + 96 = 192\n",
            "97 + 97 = 194\n",
            "98 + 98 = 196\n",
            "99 + 99 = 198\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void matrixMultiply(int *A, int *B, int *C, int N) {\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "  if (row < N && col < N) {\n",
        "    int sum = 0;\n",
        "    for (int k = 0; k < N; ++k) {\n",
        "      sum += A[row * N + k] * B[k * N + col];\n",
        "    }\n",
        "    C[row * N + col] = sum;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  int N = 2;\n",
        "  int size = N * N * sizeof(int);\n",
        "  int *A, *B, *C;\n",
        "  int *dev_A, *dev_B, *dev_C;\n",
        "\n",
        "  // Allocate memory for matrices A, B, and C on the host\n",
        "  A = (int *)malloc(size);\n",
        "  B = (int *)malloc(size);\n",
        "  C = (int *)malloc(size);\n",
        "\n",
        "  // Initialize matrices A and B\n",
        "for (int i = 0; i < N; ++i) {\n",
        "  for (int j = 0; j < N; ++j) {\n",
        "    A[i * N + j] = i + j;\n",
        "    B[i * N + j] = i * N + j;  \n",
        "  }\n",
        "}\n",
        "\n",
        "  printf(\"initial matrix A:\\n\");\n",
        "  for (int i = 0; i < N; ++i) {\n",
        "    for (int j = 0; j < N; ++j) {\n",
        "      printf(\"%d \", A[i * N + j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  printf(\"initial matrix B:\\n\");\n",
        "  for (int i = 0; i < N; ++i) {\n",
        "    for (int j = 0; j < N; ++j) {\n",
        "      printf(\"%d \", B[i * N + j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  // Allocate memory for matrices A, B, and C on the device\n",
        "  cudaMalloc(&dev_A, size);\n",
        "  cudaMalloc(&dev_B, size);\n",
        "  cudaMalloc(&dev_C, size);\n",
        "\n",
        "  // Copy matrices A and B from host to device\n",
        "  cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Define grid and block dimensions\n",
        "  dim3 dimBlock(16, 16);\n",
        "  dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (N + dimBlock.y - 1) / dimBlock.y);\n",
        "\n",
        "  // Launch the matrix multiplication kernel\n",
        "  matrixMultiply<<<dimGrid, dimBlock>>>(dev_A, dev_B, dev_C, N);\n",
        "\n",
        "  // Copy the result matrix C from device to host\n",
        "  cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Print the result matrix\n",
        "  printf(\"Result matrix C:\\n\");\n",
        "  for (int i = 0; i < N; ++i) {\n",
        "    for (int j = 0; j < N; ++j) {\n",
        "      printf(\"%d \", C[i * N + j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  // Free device memory\n",
        "  cudaFree(dev_A);\n",
        "  cudaFree(dev_B);\n",
        "  cudaFree(dev_C);\n",
        "\n",
        "  // Free host memory\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnFaemkLRJVu",
        "outputId": "54cdb71d-cdbd-4b5d-e177-172efc58f0ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial matrix A:\n",
            "0 1 \n",
            "1 2 \n",
            "initial matrix B:\n",
            "0 1 \n",
            "2 3 \n",
            "Result matrix C:\n",
            "2 3 \n",
            "4 7 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MATRIX MULTIPLICATION\n",
        "\n",
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// CUDA kernel for matrix multiplication\n",
        "__global__ void matrixMul(int* a, int* b, int* c, int rowsA, int colsA, int colsB) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int sum = 0;\n",
        "    if (row < rowsA && col < colsB) {\n",
        "        for (int i = 0; i < colsA; i++) {\n",
        "            sum += a[row * colsA + i] * b[i * colsB + col];\n",
        "        }\n",
        "        c[row * colsB + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int rowsA = 2;  // Rows of matrix A\n",
        "    int colsA = 2;  // Columns of matrix A\n",
        "    int rowsB = colsA; // Rows of matrix B\n",
        "    int colsB = 2;  // Columns of matrix B\n",
        "\n",
        "    int* a, * b, * c;  // Host matrices\n",
        "    int* dev_a, * dev_b, * dev_c;  // Device matrices\n",
        "\n",
        "    // Allocate memory for host matrices\n",
        "    a = (int*)malloc(rowsA * colsA * sizeof(int));\n",
        "    b = (int*)malloc(rowsB * colsB * sizeof(int));\n",
        "    c = (int*)malloc(rowsA * colsB * sizeof(int));\n",
        "\n",
        "    // Initialize host matrices\n",
        "    for (int i = 0; i < rowsA * colsA; i++) {\n",
        "        a[i] = i;\n",
        "    }\n",
        "    for (int i = 0; i < rowsB * colsB; i++) {\n",
        "        b[i] = 2 * i;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on the device for device matrices\n",
        "    cudaMalloc((void**)&dev_a, rowsA * colsA * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, rowsB * colsB * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, rowsA * colsB * sizeof(int));\n",
        "\n",
        "    // Copy host matrices to device\n",
        "    cudaMemcpy(dev_a, a, rowsA * colsA * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, rowsB * colsB * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 blockSize(16, 16);\n",
        "    dim3 gridSize((colsB + blockSize.x - 1) / blockSize.x, (rowsA + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "    // Launch kernel for matrix multiplication\n",
        "    matrixMul<<<gridSize, blockSize>>>(dev_a, dev_b, dev_c, rowsA, colsA, colsB);\n",
        "\n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(c, dev_c, rowsA * colsB * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print result\n",
        "    printf(\"Result:\\n\");\n",
        "    for (int i = 0; i < rowsA; i++) {\n",
        "        for (int j = 0; j < colsB; j++) {\n",
        "            printf(\"%d \", c[i * colsB + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    // Free host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QW2lcSMClp3",
        "outputId": "e88d4739-6c61-4d97-8980-9841550c4ecc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "4 6 \n",
            "12 22 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O1wsG0xlPFZX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}